{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Noorinnisask/Fmml_course_assignment/blob/main/Module_01_Lab_03_Augmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w3yfry25JgZK"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "FMML Module 1, Lab 3<br>\n",
        "\n",
        " In this lab, we will see how augmentation of data samples help in improving the machine learning performance"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZU8_elooqP0"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import mnist\n",
        "# set randomseed\n",
        "rng = np.random.default_rng(seed=42)\n",
        "from sklearn.utils.extmath import cartesian\n",
        "from skimage.transform import rotate, AffineTransform, warp\n",
        "import math"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T5pHYogSMHiE"
      },
      "source": [
        "Augmentation is useful when we have less training data available. Augmentation allows us to 'create' a larger dataset programatically.\n",
        "\n",
        "For this lab we will use a subset of MNIST that is very small, to better understand the effect of augmentation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJvmWJ58ovx5"
      },
      "source": [
        "#loading the dataset\n",
        "(train_X, train_y), (test_X, test_y) = mnist.load_data()\n",
        "train_X = train_X/255\n",
        "test_X = test_X/255\n",
        "\n",
        "train_X = train_X[::1200,:,:].copy() # subsample. Otherwise it will take too long!\n",
        "train_y = train_y[::1200].copy() # do the same to the labels"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8XamH6z1Rt7S"
      },
      "source": [
        "Let us borrow a few functions from the previous labs:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zk2W5_3BRLMS"
      },
      "source": [
        "def NN1(traindata, trainlabel, query):\n",
        "  diff  = traindata - query  # find the difference between features. Numpy automatically takes care of the size here\n",
        "  sq = diff*diff # square the differences\n",
        "  dist = sq.sum(1) # add up the squares\n",
        "  label = trainlabel[np.argmin(dist)] # our predicted label is the label of the training data which has the least distance from the query\n",
        "  return label\n",
        "\n",
        "def NN(traindata, trainlabel, testdata):\n",
        "  # we will run nearest neighbour for each sample in the test data\n",
        "  # and collect the predicted classes in an array using list comprehension\n",
        "  traindata = traindata.reshape(-1, 28*28)\n",
        "  testdata = testdata.reshape(-1,28*28)\n",
        "  predlabel = np.array([NN1(traindata, trainlabel, i) for i in testdata])\n",
        "  return predlabel\n",
        "\n",
        "def Accuracy(gtlabel, predlabel):\n",
        "  assert len(gtlabel)==len(predlabel), \"Length of the groundtruth labels and predicted labels should be the same\"\n",
        "  correct = (gtlabel==predlabel).sum() # count the number of times the groundtruth label is equal to the predicted label.\n",
        "  return correct/len(gtlabel)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eGiA3LmDSJZo"
      },
      "source": [
        "In this lab, we will use the image pixels themselves as features, instead of extracting features. Each image has 28*28 pixels, so we will flatten them to 784 pixels to use as features. Note that this is very compute intensive and will take a long time.<br>\n",
        "\n",
        "Let us check the baseline accuracy on the test set without any augmentations. We hope that adding augmentations will help us to get better results."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4tQvnoasRNEV"
      },
      "source": [
        "testpred = NN(train_X, train_y, test_X)\n",
        "print('Baseline accuracy without augmentation is ', Accuracy(test_y, testpred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZfkcMfhIZQ7U"
      },
      "source": [
        "Let us try to improve this accuracy using augmentations. When we create augmentations, we have to make sure that the changes reflect what will naturally occur in the dataset. For example, we should not add colour to our samples as an augmentation because they do not naturally occur. We should not also flip the images in MNIST, because flipped images have different meanings for digits.\n",
        "\n",
        "### Augmentation 1: rotation\n",
        "\n",
        "Let us try rotating the image a little. We will use skimage library for this."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z5WolJ9fZE7L"
      },
      "source": [
        "plt.imshow(train_X[2], cmap='gray')\n",
        "plt.show()\n",
        "plt.imshow(rotate(train_X[2],25), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KE33Yxgggu0c"
      },
      "source": [
        "After rotating, the the class of the image is still the same. Let us make a function to rotate multiple images by random angles. We want a slightly different image every time we run this function. So, we generate a random number between 0 and 1 and change it so that it lies between -constraint/2 and +constraint/2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyM7pUV7Reze"
      },
      "source": [
        "def augRotate(sample, angleconstraint):\n",
        "  if angleconstraint==0:\n",
        "    return sample\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  angle = rng.random(len(sample)) # generate random numbers for angles\n",
        "  angle = (angle-0.5)*angleconstraint # make the random angle constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = rotate(sample[ii], angle[ii])\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kDk-N5VNjar9"
      },
      "source": [
        "This function returns a slightly different image each time we call it. So we can increase the number of images in the sample by any multiple."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Vw3O9zGFgI8K"
      },
      "source": [
        "sample = train_X[20]\n",
        "angleconstraint = 70\n",
        "# show the original image\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "plt.subplot(1,3,1)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show an augmented image\n",
        "plt.subplot(1,3,2)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # show another augmented image from the same sample\n",
        "plt.subplot(1,3,3)\n",
        "plt.imshow(augRotate(sample, angleconstraint), cmap='gray') # one more image from the same sample"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ytv3NxF-kgxN"
      },
      "source": [
        "Let us augment the whole dataset and see if this improves the test accuracy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iNzNAoDBkRzj"
      },
      "source": [
        "# hyperparameters\n",
        "angleconstraint = 60\n",
        "naugmentations = 5\n",
        "\n",
        "# augment\n",
        "augdata = train_X # we include the original images also in the augmented dataset\n",
        "auglabel = train_y\n",
        "for ii in range(naugmentations):\n",
        "  augdata = np.concatenate((augdata, augRotate(train_X, angleconstraint))) # concatenate the augmented data to the set\n",
        "  auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "# check the test accuracy\n",
        "testpred = NN(augdata, auglabel, test_X)\n",
        "print('Accuracy after rotation augmentation is ', Accuracy(test_y, testpred))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E88Nt9s1p5R6"
      },
      "source": [
        "The angle constraint is a hyperparameter which we have to tune using a validation set. (Here we are not doing that for time constraints). Let us try a grid search to find the best angle constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aiaFRLREmGp6"
      },
      "source": [
        "angleconstraints = [0,10,20,30,40,50,60,70,80,90] # the values we want to test\n",
        "accuracies = np.zeros(len(angleconstraints), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(angleconstraints)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augRotate(train_X, angleconstraints[ii]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after rotation augmentation constrained by ',angleconstraints[ii], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2oVDRYP2rxob"
      },
      "source": [
        "Let us see the best value for angle constraint: (Ideally this should be done on validation set, not test set)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LqthJa_pmMHz"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "# plot the variation of accuracy\n",
        "ax.plot(angleconstraints, accuracies)\n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('accuracy')\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(angleconstraints[maxind], accuracies[maxind], c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eJ8YuVfCuGTj"
      },
      "source": [
        "Let us try one more augmentation: shear. Here is what this looks like:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pMiw46NLwssK"
      },
      "source": [
        "def shear(sample, amount):\n",
        "  tform = AffineTransform(shear = amount) # create the shear transform\n",
        "  img = warp(sample, tform) # apply the shear\n",
        "  # this makes the digit off-center. Since all the images in the test set are centralized, we will do the same here\n",
        "  col = img.sum(0).nonzero()[0]\n",
        "  row = img.sum(1).nonzero()[0]\n",
        "  if len(col)>0 and len(row)>0:\n",
        "    xshift = int(sample.shape[0]/2 - (row[0]+row[-1])/2)\n",
        "    yshift = int(sample.shape[1]/2 - (col[0]+col[-1])/2)\n",
        "    img = np.roll(img, (xshift, yshift),(0,1))\n",
        "  return img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_u_EYpmnABK"
      },
      "source": [
        "sample = train_X[2]\n",
        "plt.imshow(sample, cmap='gray')\n",
        "plt.show()\n",
        "\n",
        "# apply shear\n",
        "plt.imshow(shear(sample, 0.4), cmap='gray')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lGnWMoyM2pK4"
      },
      "source": [
        "Create an augmentation function which applies a random shear according to the constraint we provide:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qLDJyGytwP5"
      },
      "source": [
        "def augShear(sample, shearconstraint):\n",
        "  if shearconstraint==0:\n",
        "    return sample\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  amt = rng.random(len(sample)) # generate random numbers for shear\n",
        "  amt = (amt-0.5)*shearconstraint # make the random shear constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = shear(sample[ii], amt[ii])\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6lQcWW93suJ"
      },
      "source": [
        "Let us do a grid search to find the best shear constraint."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_wrqPkrzBb_"
      },
      "source": [
        "shearconstraints = [0, 0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6,1.8,2.0] # the values we want to test\n",
        "accuracies = np.zeros(len(shearconstraints), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(shearconstraints)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augShear(train_X, shearconstraints[ii]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after shear augmentation constrained by ',shearconstraints[ii], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EKaH-YR-zVnA"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "# plot the variation of accuracy\n",
        "ax.plot(shearconstraints, accuracies)\n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('accuracy')\n",
        "# plot the maximum accuracy\n",
        "maxind = np.argmax(accuracies)\n",
        "plt.scatter(shearconstraints[maxind], accuracies[maxind], c='red')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccfdbRcQ7Zgg"
      },
      "source": [
        "We can do multiple augmentations at the same time. Here is a function to do both shear and rotation to the sample. In this case, we will have two hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sh8S_Pxa0XCv"
      },
      "source": [
        "def augRotateShear(sample, angleconstraint, shearconstraint):\n",
        "  if len(sample.shape)==2:\n",
        "    sample = np.expand_dims(sample, 0)  # make sure the sample is 3 dimensional\n",
        "  amt = rng.random(len(sample)) # generate random numbers for shear\n",
        "  amt = (amt-0.5)*shearconstraint # make the random shear constrained\n",
        "  angle = rng.random(len(sample)) # generate random numbers for angles\n",
        "  angle = (angle-0.5)*angleconstraint # make the random angle constrained\n",
        "  nsample = sample.copy() # preallocate the augmented array to make it faster\n",
        "  for ii in range(len(sample)):\n",
        "    nsample[ii] = rotate(shear(sample[ii], amt[ii]), angle[ii]) # first apply shear, then rotate\n",
        "  return np.squeeze(nsample) # take care if the input had only one sample."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGKyjjNx-NQ4"
      },
      "source": [
        "Since we have two hyperparameters, we have to do the grid search on a 2 dimensional matrix. We can use our previous experience to inform where to search for the best hyperparameters."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJC45WRg0pOP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e49606d3-3999-4548-f4ef-e6c579eeda73"
      },
      "source": [
        "shearconstraints = [0, 0.2,0.4,0.6,0.8,1.0,1.2,1.4,1.6] # the values we want to test\n",
        "angleconstraints = [0,10,20,30,40,50,60] # the values we want to test\n",
        "hyp = cartesian((shearconstraints, angleconstraints)) # cartesian product of both\n",
        "\n",
        "accuracies = np.zeros(len(hyp), dtype=np.float) # we will save the values here\n",
        "\n",
        "for ii in range(len(hyp)):\n",
        "  # create the augmented dataset\n",
        "  augdata = train_X # we include the original images also in the augmented dataset\n",
        "  auglabel = train_y\n",
        "  for jj in range(naugmentations):\n",
        "    augdata = np.concatenate((augdata, augRotateShear(train_X, hyp[ii][0], hyp[ii][1]))) # concatenate the augmented data to the set\n",
        "    auglabel = np.concatenate((auglabel, train_y))  # the labels don't change when we augment\n",
        "\n",
        "  # check the test accuracy\n",
        "  testpred = NN(augdata, auglabel, test_X)\n",
        "  accuracies[ii] = Accuracy(test_y, testpred)\n",
        "  print('Accuracy after augmentation shear:',hyp[ii][0], 'angle:',hyp[ii][1], ' is ', accuracies[ii], flush=True)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-09de780976d0>:5: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  accuracies = np.zeros(len(hyp), dtype=np.float) # we will save the values here\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy after augmentation shear: 0.0 angle: 0.0  is  0.6332\n",
            "Accuracy after augmentation shear: 0.0 angle: 10.0  is  0.6151\n",
            "Accuracy after augmentation shear: 0.0 angle: 20.0  is  0.5997\n",
            "Accuracy after augmentation shear: 0.0 angle: 30.0  is  0.5915\n",
            "Accuracy after augmentation shear: 0.0 angle: 40.0  is  0.6198\n",
            "Accuracy after augmentation shear: 0.0 angle: 50.0  is  0.6031\n",
            "Accuracy after augmentation shear: 0.0 angle: 60.0  is  0.5916\n",
            "Accuracy after augmentation shear: 0.2 angle: 0.0  is  0.634\n",
            "Accuracy after augmentation shear: 0.2 angle: 10.0  is  0.5991\n",
            "Accuracy after augmentation shear: 0.2 angle: 20.0  is  0.6044\n",
            "Accuracy after augmentation shear: 0.2 angle: 30.0  is  0.6358\n",
            "Accuracy after augmentation shear: 0.2 angle: 40.0  is  0.5827\n",
            "Accuracy after augmentation shear: 0.2 angle: 50.0  is  0.579\n",
            "Accuracy after augmentation shear: 0.2 angle: 60.0  is  0.5877\n",
            "Accuracy after augmentation shear: 0.4 angle: 0.0  is  0.6344\n",
            "Accuracy after augmentation shear: 0.4 angle: 10.0  is  0.6151\n",
            "Accuracy after augmentation shear: 0.4 angle: 20.0  is  0.5988\n",
            "Accuracy after augmentation shear: 0.4 angle: 30.0  is  0.6107\n",
            "Accuracy after augmentation shear: 0.4 angle: 40.0  is  0.6177\n",
            "Accuracy after augmentation shear: 0.4 angle: 50.0  is  0.5855\n",
            "Accuracy after augmentation shear: 0.4 angle: 60.0  is  0.5893\n",
            "Accuracy after augmentation shear: 0.6 angle: 0.0  is  0.6339\n",
            "Accuracy after augmentation shear: 0.6 angle: 10.0  is  0.6191\n",
            "Accuracy after augmentation shear: 0.6 angle: 20.0  is  0.595\n",
            "Accuracy after augmentation shear: 0.6 angle: 30.0  is  0.5963\n",
            "Accuracy after augmentation shear: 0.6 angle: 40.0  is  0.6203\n",
            "Accuracy after augmentation shear: 0.6 angle: 50.0  is  0.5859\n",
            "Accuracy after augmentation shear: 0.6 angle: 60.0  is  0.6094\n",
            "Accuracy after augmentation shear: 0.8 angle: 0.0  is  0.6354\n",
            "Accuracy after augmentation shear: 0.8 angle: 10.0  is  0.6208\n",
            "Accuracy after augmentation shear: 0.8 angle: 20.0  is  0.5928\n",
            "Accuracy after augmentation shear: 0.8 angle: 30.0  is  0.5875\n",
            "Accuracy after augmentation shear: 0.8 angle: 40.0  is  0.6242\n",
            "Accuracy after augmentation shear: 0.8 angle: 50.0  is  0.5796\n",
            "Accuracy after augmentation shear: 0.8 angle: 60.0  is  0.5947\n",
            "Accuracy after augmentation shear: 1.0 angle: 0.0  is  0.6334\n",
            "Accuracy after augmentation shear: 1.0 angle: 10.0  is  0.6178\n",
            "Accuracy after augmentation shear: 1.0 angle: 20.0  is  0.6074\n",
            "Accuracy after augmentation shear: 1.0 angle: 30.0  is  0.5934\n",
            "Accuracy after augmentation shear: 1.0 angle: 40.0  is  0.6199\n",
            "Accuracy after augmentation shear: 1.0 angle: 50.0  is  0.5865\n",
            "Accuracy after augmentation shear: 1.0 angle: 60.0  is  0.5952\n",
            "Accuracy after augmentation shear: 1.2 angle: 0.0  is  0.6328\n",
            "Accuracy after augmentation shear: 1.2 angle: 10.0  is  0.5727\n",
            "Accuracy after augmentation shear: 1.2 angle: 20.0  is  0.617\n",
            "Accuracy after augmentation shear: 1.2 angle: 30.0  is  0.5852\n",
            "Accuracy after augmentation shear: 1.2 angle: 40.0  is  0.5813\n",
            "Accuracy after augmentation shear: 1.2 angle: 50.0  is  0.587\n",
            "Accuracy after augmentation shear: 1.2 angle: 60.0  is  0.6195\n",
            "Accuracy after augmentation shear: 1.4 angle: 0.0  is  0.6344\n",
            "Accuracy after augmentation shear: 1.4 angle: 10.0  is  0.6069\n",
            "Accuracy after augmentation shear: 1.4 angle: 20.0  is  0.601\n",
            "Accuracy after augmentation shear: 1.4 angle: 30.0  is  0.5848\n",
            "Accuracy after augmentation shear: 1.4 angle: 40.0  is  0.6005\n",
            "Accuracy after augmentation shear: 1.4 angle: 50.0  is  0.6045\n",
            "Accuracy after augmentation shear: 1.4 angle: 60.0  is  0.6129\n",
            "Accuracy after augmentation shear: 1.6 angle: 0.0  is  0.6369\n",
            "Accuracy after augmentation shear: 1.6 angle: 10.0  is  0.6097\n",
            "Accuracy after augmentation shear: 1.6 angle: 20.0  is  0.6078\n",
            "Accuracy after augmentation shear: 1.6 angle: 30.0  is  0.6048\n",
            "Accuracy after augmentation shear: 1.6 angle: 40.0  is  0.585\n",
            "Accuracy after augmentation shear: 1.6 angle: 50.0  is  0.5915\n",
            "Accuracy after augmentation shear: 1.6 angle: 60.0  is  0.5941\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT6CnvSDEX7a"
      },
      "source": [
        "Let us plot it two dimensionally to see which is the best value for the hyperparameters:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jD2i7msI_cLd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 481
        },
        "outputId": "a4f5e846-6233-4d99-88ae-8c05a2618432"
      },
      "source": [
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0.1, 0.1, 0.8, 0.8]) # main axes\n",
        "im = ax.imshow(accuracies.reshape((len(shearconstraints), len(angleconstraints))), cmap='inferno')\n",
        "ax.set_xlabel('angle')\n",
        "ax.set_ylabel('shear')\n",
        "ax.set_xticks(np.arange(len(angleconstraints)));\n",
        "ax.set_xticklabels(angleconstraints);\n",
        "ax.set_yticks(np.arange(len(shearconstraints)));\n",
        "ax.set_yticklabels(shearconstraints);\n",
        "plt.colorbar(im)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.colorbar.Colorbar at 0x7fddbbe8a440>"
            ]
          },
          "metadata": {},
          "execution_count": 18
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHcZWJiFJDMh"
      },
      "source": [
        "It seems that rotation and shear don't mix! The best accuracy is when rotation is zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PAasQo1C3x4A"
      },
      "source": [
        "## Questions\n",
        "Try these questions for better understanding. You may not be able to solve all of them.\n",
        "1. What is the best value for angle constraint and shear constraint you got? How much did the accuracy improve as compared to not using augmentations?\n",
        "2. Can you increase the accuracy by increasing the number of augmentations from each sample?\n",
        "3. Try implementing a few augmentations of your own and experimenting with them. A good reference is <a href=https://www.analyticsvidhya.com/blog/2019/12/image-augmentation-deep-learning-pytorch/>here. </a>\n",
        "4. Try combining various augmentations. What is the highest accuracy you can get? What is the smallest training dataset you can take and still get accuracy above 50%?\n",
        "\n",
        "Whenever you do any experiment, a good practice is to vary the hyperparameters gradually and create a graph of your results, like we did for gridsearch."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***1question answer***\n",
        "Increasing the number of iterations is not a solution for dealing with very small training or validation datasets. In fact, trying to compensate for a small dataset by increasing the number of iterations may lead to overfitting, which is a situation where the model becomes too specific to the limited data available. This can result in poor generalization to unseen data.\n",
        "\n",
        "When you have a small dataset, it's essential to be cautious and consider other strategies to address the data limitations:\n",
        "\n",
        "Data Augmentation: If applicable, use data augmentation techniques to artificially increase the effective size of your training dataset by creating new, slightly modified examples.\n",
        "\n",
        "Regularization: Apply regularization techniques such as L1 and L2 regularization to prevent overfitting, as they can help the model generalize better even with limited data.\n",
        "\n",
        "Transfer Learning: If relevant, leverage pre-trained models and transfer learning to benefit from knowledge learned on larger, related datasets. Fine-tuning can be applied to adapt the pre-trained model to your specific task with a small dataset.\n",
        "\n",
        "Data Splitting: Be cautious with data splitting. Ensure that you allocate a reasonable portion of your data to the validation dataset, but it's also important to have a sufficient amount left for training.\n",
        "\n",
        "Feature Engineering: Thoughtful feature engineering can help extract more information from a small dataset.\n",
        "\n",
        "Ensemble Methods: Combine multiple models to improve predictive performance. Ensembling can help compensate for data limitations.\n",
        "\n",
        "In summary, increasing the number of iterations is not a substitute for insufficient data. It's crucial to take steps to address the challenges of small datasets through other means, focusing on data quality, model regularization, and leveraging domain knowledge where possible."
      ],
      "metadata": {
        "id": "i9jCywpE-1wc"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***2question answer***\n",
        " Yes, increasing the number of augmentations from each sample can sometimes improve accuracy, but it should be done carefully to avoid overfitting. Finding the right balance is key for better model performance."
      ],
      "metadata": {
        "id": "mPqicjxS_BN3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***3question answer***\n",
        "Certainly! You can experiment with image augmentations like rotation, flip, brightness adjustments, zoom, noise, color changes, and blur to improve your model's performance. Libraries like OpenCV and PIL in Python can help you implement these augmentations."
      ],
      "metadata": {
        "id": "t4wkAjMf_Kyx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#***4question answer***\n",
        "I don't have the capability to conduct experiments, so I can't provide specific accuracy values or dataset sizes for your particular task. The highest accuracy achievable by combining augmentations depends on various factors including the dataset, the model architecture, and the problem you're trying to solve. To find the smallest training dataset size while maintaining an accuracy above 50%, you'll need to experiment with different combinations of augmentations and evaluate your model's performance through cross-validation or a validation dataset. This process will help you determine the optimal dataset size and augmentation strategy for your specific problem."
      ],
      "metadata": {
        "id": "Q2Xskx8E_Srg"
      }
    }
  ]
}